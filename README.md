Purpose is to learn spark and apply basic machine learning model. 

Using the California housing data, the purpose is to predict the housing value per block group. 
The main approach is to use spark functions to perform EDA, Feature Engineering and predictions. 

How to run:
1. terminal >> jupyter notebook
2. open file, run each cell line

Experience: It was a great learning tool, I broke down some the fundamentals and wrote it down on each cell. 
The most important element was reviewing how Spark operates and how it distributes the work/resources

Future works:
Docker implimentation
Hyper parameter turning

Resources:
1. https://spark.apache.org/docs/latest/cluster-overview.html
2. https://www.mygreatlearning.com/blog/pyspark-tutorial-a-beginners-guide-2021/
3. https://developer.hpe.com/blog/spark-101-what-is-it-what-it-does-and-why-it-matters/
4. https://medium.com/analytics-vidhya/l1-vs-l2-regularization-which-is-better-d01068e6658c
5. https://towardsdatascience.com/your-first-apache-spark-ml-model-d2bb82b599dd
6. https://www.analyticssteps.com/blogs/linear-lasso-ridge-and-elastic-net-regression-overview
7. https://machinelearningmastery.com/elastic-net-regression-in-python/
8. https://www.kaggle.com/fatmakursun/pyspark-ml-tutorial-for-beginners
9. https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html